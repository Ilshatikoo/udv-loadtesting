### Стратегия для нагрузочного тестирования:

#### Шаги, необходимые для реализации тестирования:

- **Понимание окружения:**
  - Изучение развернутых сервисов, настроек ВМ, тип железа и возможных ограничений по ресурсам самих контейнеров.
  - Уточнение требований к работе сервиса, определение необходимой нагрузки и прочих параметров.

- **Мониторинг и подготовка:**
  - Настройка системы мониторинга.
  - Создание сценариев для нагрузочного тестирования.


- **Выполнение тестов:**
  - Выполнение и корректировка тестов в соответствии с результатами.

- **Как развивать нагрузочное тестирование и тестирование производительности в дальнейшем?**
  - Расширение сценариев тестирования
  - Автоматизация тестирования
  - Сравнивать разные итерации(например сравнить разные релизы, etc) для понимания продолжает ли работать сервис хорошо.
  - Корректировка SLA.

- **Какие инструменты планируете использовать?**
  - K6 как основной инструмент нагрузки

В нагрузочном тестировании системы будем делать упор на пользовательские сценарии использования т.е сценарии нагрузочного тестирования будут основаны на действиях пользователя. Дополнительные нагрузочные тесты будут создаваться для выявления проблем в отдельных сервисах. Для продукта уже есть ряд метрик, по которым вся наша система должна проходит, а значит минимальные значения для сценария нагрузки у нас уже есть. Далее же будем итеративно поднимать нагрузку и смотреть как будет вести себя система и уже будут понятны пределы работы сервисов. 

### Цели и задачи нагрузочного тестирования:

- **Проверка производительности:**
  - Оценка работы системы при максимальной нагрузке.
  - Идентификация узких мест в системе.
  - Оценка соответствия системы SLA.

### Узкие места, которые могут быть:

- **База данных:** Может стать узким местом при большом количестве пользователей и виртуальных машин, а также при неправильной работе db_proxy(аля наплодил коннекшинов).
- **Сервисы IP Collector и VM Manager:** Возможны узкие места при высокой нагрузке, т.к скорее всего эти два сервиса будут получать максимальную нагрузку.
- **External management proxy:** Этот сервис может пострадать в случае, если пойдет большой дудос на сервисы и система не справится с отдачей большого количества аллертов
- **RabbitMQ:** может упасть при больших запросах. Опять же какой кролик? Если это отказоустойчивый кластер, то всё ок. Если это один инстанс, то тут уже вопросики. На практике есть опыт, когда отдельно поднятый кролик в одном экземпляре падал

### Мониторинг:

- **Инструменты мониторинга:**
  - Grafana для визуализации.
  - InfluxDB для хранения метрик тестирования.
  - ELK (Kibana, Elastic) для просмотра логов сервисов(если они есть).
  - Настройка экспортеров для получения данных по железу, RabbitMQ, и базе данных, включая Prometheus как хранилище данных.
  - Ну и zabbix опять же для железа. Вообще плюс заббикста это то что он собирает все данные которые может и в случае краха какой либо системы будет удобно смотреть графики и выявлять аномалии.  

- **Ключевые метрики:**
  - Время отклика API.
  - Загрузка CPU и памяти ВМ(а может и контейнеров).
  - Пропускная способность сети.
  - Количество пакетов в кролике(как ориентир что пакеты отдаются/не отдаются)
  - Количество запросов к базе данных и очередям.
  - Время создания ВМок(под вопросом)

### Тестирование производительности отдельных сервисов:

- **Переход к модульным тестам:**
Решение о переходе будет зависеть от итогов результатов тестирования системы. При обнаружении проблем в отдельных сервисах будут проводиться тесты на уровне модулей для выявления и решения проблем. Также в случае, если нужно будет отслеживать деградацию сервиса, то нагрузочные тесты нужно будет встраивать в CI/CD на уровне отдельных модулей.